{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00,  2.8815e-01,  4.7097e-01,  ..., -4.7097e-01,\n",
      "        -2.8815e-01,  1.9644e-15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/hh/anaconda3/envs/trajectoryZSL/lib/python3.9/site-packages/torch/functional.py:704: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:873.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n",
      "/tmp/ipykernel_2763197/1488607.py:28: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  plt.imshow(magnitude.T.numpy(), aspect='auto', origin='lower', extent=[0, 1, 0, fs / 2])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (2, 9, 129) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 绘制 STFT 幅度谱\u001b[39;00m\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 28\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmagnitude\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlower\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMagnitude\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency (Hz)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/trajectoryZSL/lib/python3.9/site-packages/matplotlib/pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3543\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3561\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3562\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m     sci(__ret)\n\u001b[1;32m   3582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/trajectoryZSL/lib/python3.9/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/trajectoryZSL/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trajectoryZSL/lib/python3.9/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trajectoryZSL/lib/python3.9/site-packages/matplotlib/image.py:697\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    695\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (2, 9, 129) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成一个示例信号：1秒的正弦波\n",
    "fs = 1024  # 采样频率\n",
    "t = np.linspace(0, 1, fs)\n",
    "signal = .5 * np.sin(2 * np.pi * 100 * t)  # 100Hz 正弦波\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "signal_tensor = torch.tensor(signal, dtype=torch.float32)\n",
    "print(signal_tensor)\n",
    "# STFT 参数\n",
    "n_fft = 256\n",
    "hop_length = 128\n",
    "win_length = 256\n",
    "window = torch.hann_window(win_length)\n",
    "\n",
    "# 计算 STFT\n",
    "stft_result = torch.stft(signal_tensor, n_fft=n_fft, hop_length=hop_length,\n",
    "                         win_length=win_length, window=window, return_complex=True)\n",
    "\n",
    "# 获取幅度谱\n",
    "magnitude = torch.abs(stft_result)\n",
    "\n",
    "# 绘制 STFT 幅度谱\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(magnitude.T.numpy(), aspect='auto', origin='lower', extent=[0, 1, 0, fs / 2])\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title('STFT Magnitude Spectrum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Mahalanobis module\n",
    "--------------------------\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MahalanobisLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, decay = 0.1):\n",
    "        super(MahalanobisLayer, self).__init__()\n",
    "        self.S = torch.eye(dim)\n",
    "        self.S_inv = torch.eye(dim)\n",
    "        self.decay = decay\n",
    "\n",
    "    def forward(self, x, x_fit):\n",
    "        \"\"\"\n",
    "        Calculates the squared Mahalanobis distance between x and x_fit\n",
    "        \"\"\"\n",
    "\n",
    "        delta = x - x_fit\n",
    "        m = torch.matmul(torch.matmul(delta, self.S_inv), delta.t())\n",
    "        return torch.diag(m)\n",
    "\n",
    "    def cov(self, x):\n",
    "        x -= torch.mean(x, dim=0)\n",
    "        return 1 / (x.size(0) - 1) * x.t().matmul(x)\n",
    "\n",
    "    def update(self, X, X_fit):\n",
    "        \"\"\"更新过程会让S渐渐接近于样本X和参考点X_fit的差值(delta = X - X_fit)的协方差。\n",
    "        \"\"\"\n",
    "        delta = X - X_fit\n",
    "        self.S = (1 - self.decay) * self.S + self.decay * self.cov(delta)\n",
    "        self.S_inv = torch.pinverse(self.S)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    from scipy.spatial import distance\n",
    "    import numpy as np\n",
    "\n",
    "    # Some example data for testing\n",
    "    v  = torch.Tensor([[1, 0.5, 0.5], [0.5, 1, 0.5], [0.5, 0.5, 1]])\n",
    "    iv = torch.inverse(v)\n",
    "    X1 = torch.Tensor([[1, 0, 0], [0, 1, 0], [0, 2, 0]])\n",
    "    X2 = torch.Tensor([[0, 1, 0], [0, 2, 0], [0, 2, 0]])\n",
    "\n",
    "    # Squared Mahalanobis distance using scipy\n",
    "    scipy_dist_list = [distance.mahalanobis(x1.numpy(), x2.numpy(), iv.numpy()) for x1, x2 in zip(X1, X2)]\n",
    "    scipy_dist = np.array(scipy_dist_list)**2\n",
    "\n",
    "    # Mahalanobis distance pytorch implementation\n",
    "    mah_layer = MahalanobisLayer(3, decay=0.99)\n",
    "    mah_layer.S_inv = iv\n",
    "\n",
    "    pytorch_dist = mah_layer(X1, X2)\n",
    "\n",
    "     # Check if almost equal\n",
    "    np.testing.assert_almost_equal(scipy_dist, pytorch_dist.numpy())\n",
    "\n",
    "    # Covariance method\n",
    "    X = torch.rand(10, 3)\n",
    "    np_cov_X = np.cov(X.numpy(), rowvar=False)\n",
    "    pytorch_cov_X = mah_layer.cov(X)\n",
    "\n",
    "    # Check if almost equal\n",
    "    np.testing.assert_almost_equal(np_cov_X, pytorch_cov_X.numpy())\n",
    "\n",
    "    # Update method\n",
    "    X_fit = torch.rand(10, 3)\n",
    "    delta = X - X_fit\n",
    "    np_cov_delta = np.cov(delta.numpy(), rowvar=False)\n",
    "    pytorch_cov_delta = mah_layer.cov(delta)\n",
    "    np.testing.assert_almost_equal(np_cov_delta, pytorch_cov_delta.numpy())\n",
    "\n",
    "    # Check if almost equal after enough updates\n",
    "    for i in range(20):\n",
    "        mah_layer.update(X, X_fit)\n",
    "    np.testing.assert_almost_equal(np_cov_delta, mah_layer.S.numpy())\n",
    "\n",
    "    # Test if numpy inverse and pytorch pseudo inverse are close\n",
    "    np.testing.assert_almost_equal(np.linalg.inv(np_cov_delta), mah_layer.S_inv.numpy(), decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "tensor([[       nan,        nan,        nan, 27409.7793,        nan,        nan,\n",
      "                nan, 15270.6250,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7891,        nan,        nan,\n",
      "                nan, 15270.6045,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7773,        nan,        nan,\n",
      "                nan, 15270.5928,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.8105,        nan,        nan,\n",
      "                nan, 15270.6182,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7930,        nan,        nan,\n",
      "                nan, 15270.6240,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7812,        nan,        nan,\n",
      "                nan, 15270.5957,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7910,        nan,        nan,\n",
      "                nan, 15270.6045,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7930,        nan,        nan,\n",
      "                nan, 15270.6182,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7598,        nan,        nan,\n",
      "                nan, 15270.5996,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7598,        nan,        nan,\n",
      "                nan, 15270.6025,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7891,        nan,        nan,\n",
      "                nan, 15270.6211,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7871,        nan,        nan,\n",
      "                nan, 15270.6084,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7656,        nan,        nan,\n",
      "                nan, 15270.5820,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.8027,        nan,        nan,\n",
      "                nan, 15270.6055,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7949,        nan,        nan,\n",
      "                nan, 15270.6260,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7930,        nan,        nan,\n",
      "                nan, 15270.6016,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7832,        nan,        nan,\n",
      "                nan, 15270.6230,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.8008,        nan,        nan,\n",
      "                nan, 15270.6279,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7520,        nan,        nan,\n",
      "                nan, 15270.6006,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7656,        nan,        nan,\n",
      "                nan, 15270.5898,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7812,        nan,        nan,\n",
      "                nan, 15270.6074,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7930,        nan,        nan,\n",
      "                nan, 15270.6211,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7949,        nan,        nan,\n",
      "                nan, 15270.6094,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7812,        nan,        nan,\n",
      "                nan, 15270.6113,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7715,        nan,        nan,\n",
      "                nan, 15270.6016,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7891,        nan,        nan,\n",
      "                nan, 15270.6328,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7695,        nan,        nan,\n",
      "                nan, 15270.6182,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7812,        nan,        nan,\n",
      "                nan, 15270.6172,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7988,        nan,        nan,\n",
      "                nan, 15270.6377,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7871,        nan,        nan,\n",
      "                nan, 15270.6113,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7949,        nan,        nan,\n",
      "                nan, 15270.6182,        nan,        nan],\n",
      "        [       nan,        nan,        nan, 27409.7598,        nan,        nan,\n",
      "                nan, 15270.5771,        nan,        nan]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def mahalanobis_distance(X, centers):\n",
    "    # 计算协方差矩阵 (features_dim, features_dim)\n",
    "    # 使用样本 X 估计协方差矩阵并计算逆矩阵\n",
    "    cov_matrix = torch.cov(X.T)  # 假设 X 沿第0维是样本数，第1维是特征数\n",
    "    cov_inv = torch.linalg.inv(cov_matrix)  # 计算协方差矩阵的逆\n",
    "\n",
    "    # 扩展 X 和 centers 的维度以便进行广播计算\n",
    "    X_expanded = X.unsqueeze(1)  # (batch_size, 1, features_dim)\n",
    "    centers_expanded = centers.unsqueeze(0)  # (1, num_class, features_dim)\n",
    "\n",
    "    # 计算每个样本与每个中心之间的差\n",
    "    diff = X_expanded - centers_expanded  # (batch_size, num_class, features_dim)\n",
    "\n",
    "    # 计算马氏距离的平方\n",
    "    # 距离公式：sqrt((x - c)^T * cov_inv * (x - c))\n",
    "    # 这里计算平方距离以避免开根号的开销\n",
    "    mahalanobis_squared = torch.einsum('bcd,de,bce->bc', diff, cov_inv, diff)\n",
    "\n",
    "    # 返回距离 (batch_size, num_class)\n",
    "    return torch.sqrt(mahalanobis_squared)\n",
    "\n",
    "# 示例数据\n",
    "batch_size, features_dim, num_class = 32, 128, 10\n",
    "X = torch.randn(batch_size, features_dim)\n",
    "centers = torch.randn(num_class, features_dim)\n",
    "\n",
    "# 计算马氏距离\n",
    "distances = mahalanobis_distance(X, centers)\n",
    "print(distances.shape)  # 应该输出 (batch_size, num_class)\n",
    "print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.66752185 -1.34429169  0.73768066]\n",
      " [ 1.20680026  0.51541657  1.24121191]\n",
      " [ 0.0030893   0.62537553 -1.49405552]\n",
      " [-0.34489145 -1.01972802  0.28931678]\n",
      " [ 0.80252373  1.22322762 -0.77415383]]\n",
      "[[0.         0.         0.81591151]\n",
      " [1.         0.72432104 1.        ]\n",
      " [0.58121918 0.76714797 0.        ]\n",
      " [0.46015386 0.12641138 0.65199193]\n",
      " [0.85934891 1.         0.26319243]]\n",
      "[[0.77532853 0.45971716 0.20698515 0.73934547]\n",
      " [0.69050825 0.749755   0.17331201 0.47961225]\n",
      " [0.49453489 0.07784619 0.19549354 0.92409771]]\n",
      "归一化到 [0, 1]: [[1.         0.5683375  1.         0.58434581]\n",
      " [0.69792663 1.         0.         0.        ]\n",
      " [0.         0.         0.65873067 1.        ]]\n",
      "归一化到 [-1, 1]: [[ 1.          0.136675    1.          0.16869162]\n",
      " [ 0.39585325  1.         -1.         -1.        ]\n",
      " [-1.         -1.          0.31746134  1.        ]]\n",
      "归一化到 [10, 20]: [[20.         15.683375   20.         15.8434581 ]\n",
      " [16.97926627 20.         10.         10.        ]\n",
      " [10.         10.         16.5873067  20.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 示例二维ndarray\n",
    "arr = np.random.rand(5, 3)  # 创建一个5x3的二维数组\n",
    "\n",
    "# Z-Score 标准化\n",
    "arr_standardized = (arr - arr.mean(axis=0)) / arr.std(axis=0)\n",
    "\n",
    "print(arr_standardized)\n",
    "\n",
    "# 最小-最大归一化\n",
    "arr_normalized = (arr - arr.min(axis=0)) / (arr.max(axis=0) - arr.min(axis=0))\n",
    "\n",
    "print(arr_normalized)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_to_range(matrix: np.ndarray, a, b, axis=0):\n",
    "    \"\"\"\n",
    "    将数据归一化到指定的范围 [a, b]\n",
    "    \"\"\"\n",
    "    # 计算数据的最小值和最大值\n",
    "    min_val = matrix.min(axis=0)\n",
    "    max_val = matrix.max(axis=0)\n",
    "    \n",
    "    # 归一化公式\n",
    "    return a + (matrix - min_val) * (b - a) / (max_val - min_val) \n",
    "\n",
    "# 示例数据\n",
    "data = np.random.rand(3, 4)\n",
    "print(data)\n",
    "\n",
    "# 归一化到 [0, 1] 范围\n",
    "normalized_data_0_1 = normalize_to_range(data, 0, 1)\n",
    "print(\"归一化到 [0, 1]:\", normalized_data_0_1)\n",
    "\n",
    "# 归一化到 [-1, 1] 范围\n",
    "normalized_data_minus1_1 = normalize_to_range(data, -1, 1)\n",
    "print(\"归一化到 [-1, 1]:\", normalized_data_minus1_1)\n",
    "\n",
    "# 归一化到 [10, 20] 范围\n",
    "normalized_data_10_20 = normalize_to_range(data, 10, 20)\n",
    "print(\"归一化到 [10, 20]:\", normalized_data_10_20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16]) torch.Size([16]) torch.Size([16, 3712])\n",
      "tensor([122.9405,  18.3659,  18.3183,  18.1921,  18.1441,  17.9775,  17.7609,\n",
      "         17.6385,  17.5347,  17.4124,  17.2192,  17.1543,  17.0958,  17.0253,\n",
      "         16.8236,  16.5582])\n",
      "torch.Size([16, 3712])\n",
      "降维后的矩阵形状: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例数据\n",
    "bs = 16  # batch size\n",
    "original_dim = 3712  # 原始特征维度\n",
    "target_dim = 128  # 降维后的目标维度\n",
    "A = torch.rand(bs, original_dim)  # bs × 3712 输入矩阵\n",
    "\n",
    "# SVD 分解\n",
    "U, S, Vh = torch.linalg.svd(A, full_matrices=False)  # full_matrices=False 保持矩阵紧凑\n",
    "print(U.shape, S.shape, Vh.shape)\n",
    "print(S)\n",
    "\n",
    "# 获取前 128 个右奇异向量\n",
    "V_k = Vh[:target_dim, :]  # Shape: 128 × 3712\n",
    "print(V_k.shape)\n",
    "\n",
    "# 降维\n",
    "A_lowdim = torch.matmul(A, V_k.T)  # Shape: bs × 128\n",
    "\n",
    "print(\"降维后的矩阵形状:\", A_lowdim.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出张量大小: torch.Size([8, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 输入张量，大小为 (batch_size, length)\n",
    "x = torch.randn(8, 3712)\n",
    "\n",
    "# 定义 MaxPool1d\n",
    "pool = nn.MaxPool1d(kernel_size=29, stride=29)\n",
    "\n",
    "# 输入需要 (batch_size, channels, length)，所以需要增加一个维度\n",
    "x = x.unsqueeze(1)  # (8, 1, 3712)\n",
    "\n",
    "# 应用 MaxPool1d\n",
    "output = pool(x)\n",
    "\n",
    "# 去掉多余的通道维度，得到 (8, 128)\n",
    "output = output.squeeze(1)\n",
    "\n",
    "print(\"输出张量大小:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenMax Probabilities: [0.25151812 0.2385841  0.13715605 0.0243315 ]\n",
      "Unknown Probability: 1.0507136930072312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import weibull_min\n",
    "\n",
    "# 模拟 logits 输出\n",
    "logits = np.array([5.2, 4.8, 2.1, 0.3])\n",
    "\n",
    "# 拟合 Weibull 分布\n",
    "def fit_weibull(data, tail_size=20):\n",
    "    tail_data = np.sort(data)[-tail_size:]\n",
    "    params = weibull_min.fit(tail_data, floc=0)  # 固定位置参数为0\n",
    "    return params\n",
    "\n",
    "# 计算未知类概率\n",
    "def compute_openmax(logits, weibull_params, alpha=0.5):\n",
    "    weibull_probs = weibull_min.cdf(logits, *weibull_params)\n",
    "    adjusted_logits = logits * (1 - alpha * weibull_probs)\n",
    "    unknown_prob = alpha * np.sum(weibull_probs)\n",
    "    return adjusted_logits / np.sum(adjusted_logits + unknown_prob), unknown_prob\n",
    "\n",
    "# 应用 OpenMax\n",
    "weibull_params = fit_weibull(logits)\n",
    "openmax_probs, unknown_prob = compute_openmax(logits, weibull_params)\n",
    "print(\"OpenMax Probabilities:\", openmax_probs)\n",
    "print(\"Unknown Probability:\", unknown_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.01874175 11.76571703 10.58459869 11.61570557 11.21244446 10.52630716\n",
      " 11.09870516 10.76711366 10.89501091 12.32151988 12.5795593  10.83433527\n",
      " 11.38221591 10.7924245  11.12731775 10.70461625 11.82805647 11.38345948\n",
      " 11.66753593 10.77452181 12.22715917 11.83175608 10.98122375 10.39863107\n",
      "  9.06585123 11.09347382 10.96421381 11.48040476 11.68577522 11.60441552\n",
      " 11.79457471 10.89300404 10.15933623 12.12547682 10.73686614 11.13002006\n",
      " 11.49314911 10.73224076 10.9001735  11.28216874 11.78818773  9.77414735\n",
      " 11.44855676 11.10519248 11.64153779 11.32703733 11.13165524 10.87437316\n",
      " 12.0591956  10.24899812 12.86040043 11.79688388 10.61788741 11.59135318\n",
      " 12.46674211 10.84673819 12.11190916 11.97468296 11.72750004 12.21413406\n",
      " 11.1555743  12.24774043 11.38473073 11.24376168 11.63972657 10.08083924\n",
      " 11.64481403 11.70709865 12.41056868 11.02839886 12.33312232 11.53808386\n",
      " 10.88979158 11.32265164 11.87626803 10.63156648 10.33319771 10.83257812\n",
      " 12.54859864 11.56716153 12.89491643 10.88661108 10.85436158 12.08569489\n",
      " 11.61985505 12.32476774 10.66280902 10.75644257 11.57415239 11.8822506\n",
      " 12.88548395 12.28356958 10.46505766 11.89677787 11.60660104 10.11714558\n",
      " 11.46045524 11.32197762 12.00290054 10.65111677]\n",
      "(np.float64(0.3382119888157475), np.float64(11.11280550731376), np.float64(0.7415225373677397))\n",
      "12.502382363152707\n",
      "Unknown Samples: 5\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import genextreme\n",
    "import numpy as np\n",
    "\n",
    "# 模拟特征嵌入和类别中心\n",
    "features = np.random.randn(100, 128)  # 100个样本，128维特征\n",
    "class_centers = np.mean(features[:50], axis=0)  # 假设前50个样本为一个类别\n",
    "\n",
    "# 计算欧几里得距离\n",
    "distances = np.linalg.norm(features - class_centers, axis=1)\n",
    "\n",
    "print(distances)\n",
    "\n",
    "# 极值分布拟合\n",
    "params = genextreme.fit(distances)\n",
    "threshold = genextreme.ppf(0.95, *params)  # 95%置信区间\n",
    "\n",
    "print(params)\n",
    "print(threshold)\n",
    "\n",
    "# 判定未知类\n",
    "is_unknown = distances > threshold\n",
    "print(\"Unknown Samples:\", np.sum(is_unknown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6354, 4.4105, 4.4418, 4.7746, 4.4876, 4.4894, 3.9661, 4.8454, 4.2868,\n",
      "        4.3154])\n",
      "tensor([42.6876, 40.2674, 41.4844, 44.9314, 42.3701, 41.6341, 36.9546, 44.5891,\n",
      "        39.2722, 37.7717])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def calculate_distance(centers: nn.Parameter, feature: torch.Tensor, mode=\"mahalanobis\") -> torch.Tensor:\n",
    "    \"\"\"计算特征向量到所有聚类中心的平方马氏距离\n",
    "    Args:\n",
    "        centers (nn.Parameter): 聚类中心向量 [num_class, features_dim]\n",
    "        feature (torch.Tensor): 特征向量 [1, features_dim]\n",
    "    Returns:\n",
    "        torch.Tensor: 特征向量到每个聚类中心的马氏距离 [num_class(seen), 1]\n",
    "    \"\"\"\n",
    "    if mode == \"euclidan\":\n",
    "        return torch.stack([torch.norm(feature - center, p=2) for center in centers])\n",
    "    elif mode == \"manhattan\":\n",
    "        return torch.stack([torch.norm(feature - center, p=1) for center in centers])\n",
    "\n",
    "centers = torch.rand((10, 128))\n",
    "feature = torch.rand((128))\n",
    "print(calculate_distance(centers, feature, mode=\"euclidan\"))\n",
    "print(calculate_distance(centers, feature, mode=\"manhattan\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (16, 1024)\n",
      "Reduced Shape: (16, 10)\n",
      "Approximated Shape: (16, 1024)\n",
      "tensor(21.0944)\n",
      "[[0.37454012 0.95071431 0.73199394 ... 0.29734901 0.9243962  0.97105825]\n",
      " [0.94426649 0.47421422 0.86204265 ... 0.7228143  0.06766836 0.7078351 ]\n",
      " [0.54353822 0.08172535 0.45830064 ... 0.67602629 0.70662987 0.61000742]\n",
      " ...\n",
      " [0.18655791 0.63634432 0.50009234 ... 0.24051204 0.30666863 0.96157897]\n",
      " [0.57847325 0.98759577 0.37246695 ... 0.92701211 0.39837768 0.31909534]\n",
      " [0.887142   0.0492444  0.13638539 ... 0.59986797 0.52649853 0.5162331 ]]\n",
      "[[0.38563325 0.93318332 0.64777004 ... 0.14552541 0.85137964 0.8501877 ]\n",
      " [0.95952628 0.48569005 0.87120395 ... 0.8054927  0.12872458 0.71514665]\n",
      " [0.57250968 0.06350062 0.43459888 ... 0.50661032 0.55204896 0.73501694]\n",
      " ...\n",
      " [0.17838214 0.47521749 0.4068248  ... 0.34625473 0.51758096 0.79919515]\n",
      " [0.4686142  0.87526944 0.4965454  ... 0.93479001 0.58163588 0.30097545]\n",
      " [0.73749571 0.19512569 0.3627128  ... 0.58038754 0.57141379 0.43752195]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# 假设输入矩阵为 X，大小为 (16, 1024)\n",
    "np.random.seed(42)  # 保持结果可重复\n",
    "X = np.random.rand(16, 1024)\n",
    "\n",
    "# SVD 分解\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "# 保留前 16 个奇异值对应的成分\n",
    "U_reduced = U[:, :10]  # 左奇异向量\n",
    "S_reduced = np.diag(S[:10])  # 奇异值矩阵（对角阵）\n",
    "Vt_reduced = Vt[:10, :]  # 右奇异向量\n",
    "\n",
    "# 得到降维后的矩阵（映射到低维空间）\n",
    "X_reduced = np.dot(U_reduced, S_reduced)\n",
    "\n",
    "# 如果需要恢复降维后的近似矩阵，可以使用以下方式\n",
    "X_approx = np.dot(X_reduced, Vt_reduced)\n",
    "\n",
    "print(\"Original Shape:\", X.shape)\n",
    "print(\"Reduced Shape:\", X_reduced.shape)\n",
    "print(\"Approximated Shape:\", X_approx.shape)\n",
    "print(torch.dist(torch.Tensor(X), torch.Tensor(X_approx)))\n",
    "print(X)\n",
    "print(X_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0697,  0.5385,  0.0000,  0.3007,  2.6710,  0.0000, -3.6726, -0.1665,\n",
      "         0.3158,  1.4074])\n",
      "tensor([ 1.0392, -0.5477, -0.0000, -2.2065, -0.7184,  0.0000,  0.7324,  1.9952,\n",
      "         1.8829, -0.5398])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SharedDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(SharedDropout, self).__init__()\n",
    "        self.p = p\n",
    "        self.scale = 1.0 / (1.0 - p)  # 为了保持输出期望值不变\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # 生成相同的掩码 (同样的随机掩码)\n",
    "        if self.training:  # 只在训练模式下使用 dropout\n",
    "            mask = (torch.rand_like(x1) > self.p).float()  # 生成0和1的掩码\n",
    "            mask = mask * self.scale  # 对保留的单元进行缩放\n",
    "            # 应用相同的掩码到两个输入上\n",
    "            x1 = x1 * mask\n",
    "            x2 = x2 * mask\n",
    "        return x1, x2\n",
    "\n",
    "# 测试代码\n",
    "x1 = torch.randn(10)  # 假设是第一个输入\n",
    "x2 = torch.randn(10)  # 假设是第二个输入\n",
    "\n",
    "dropout_layer = SharedDropout(p=0.3)  # 创建共享Dropout层，丢弃概率为30%\n",
    "\n",
    "# 训练模式下\n",
    "dropout_layer.train()\n",
    "\n",
    "out1, out2 = dropout_layer(x1, x2)\n",
    "print(out1)\n",
    "print(out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoNCE Loss: 2.803877115249634\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "__all__ = ['InfoNCE', 'info_nce']\n",
    "\n",
    "\n",
    "class InfoNCE(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the InfoNCE loss for self-supervised learning.\n",
    "    This contrastive loss enforces the embeddings of similar (positive) samples to be close\n",
    "        and those of different (negative) samples to be distant.\n",
    "    A query embedding is compared with one positive key and with one or more negative keys.\n",
    "\n",
    "    References:\n",
    "        https://arxiv.org/abs/1807.03748v2\n",
    "        https://arxiv.org/abs/2010.05113\n",
    "\n",
    "    Args:\n",
    "        temperature: Logits are divided by temperature before calculating the cross entropy.\n",
    "        reduction: Reduction method applied to the output.\n",
    "            Value must be one of ['none', 'sum', 'mean'].\n",
    "            See torch.nn.functional.cross_entropy for more details about each option.\n",
    "        negative_mode: Determines how the (optional) negative_keys are handled.\n",
    "            Value must be one of ['paired', 'unpaired'].\n",
    "            If 'paired', then each query sample is paired with a number of negative keys.\n",
    "            Comparable to a triplet loss, but with multiple negatives per sample.\n",
    "            If 'unpaired', then the set of negative keys are all unrelated to any positive key.\n",
    "\n",
    "    Input shape:\n",
    "        query: (N, D) Tensor with query samples (e.g. embeddings of the input).\n",
    "        positive_key: (N, D) Tensor with positive samples (e.g. embeddings of augmented input).\n",
    "        negative_keys (optional): Tensor with negative samples (e.g. embeddings of other inputs)\n",
    "            If negative_mode = 'paired', then negative_keys is a (N, M, D) Tensor.\n",
    "            If negative_mode = 'unpaired', then negative_keys is a (M, D) Tensor.\n",
    "            If None, then the negative keys for a sample are the positive keys for the other samples.\n",
    "\n",
    "    Returns:\n",
    "         Value of the InfoNCE Loss.\n",
    "\n",
    "     Examples:\n",
    "        >>> loss = InfoNCE()\n",
    "        >>> batch_size, num_negative, embedding_size = 32, 48, 128\n",
    "        >>> query = torch.randn(batch_size, embedding_size)\n",
    "        >>> positive_key = torch.randn(batch_size, embedding_size)\n",
    "        >>> negative_keys = torch.randn(num_negative, embedding_size)\n",
    "        >>> output = loss(query, positive_key, negative_keys)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temperature=0.1, reduction='mean', negative_mode='unpaired'):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.reduction = reduction\n",
    "        self.negative_mode = negative_mode\n",
    "\n",
    "    def forward(self, query, positive_key, negative_keys=None):\n",
    "        return info_nce(query, positive_key, negative_keys,\n",
    "                        temperature=self.temperature,\n",
    "                        reduction=self.reduction,\n",
    "                        negative_mode=self.negative_mode)\n",
    "\n",
    "\n",
    "def info_nce(query, positive_key, negative_keys=None, temperature=0.1, reduction='mean', negative_mode='unpaired'):\n",
    "    # Check input dimensionality.\n",
    "    if query.dim() != 2:\n",
    "        raise ValueError('<query> must have 2 dimensions.')\n",
    "    if positive_key.dim() != 2:\n",
    "        raise ValueError('<positive_key> must have 2 dimensions.')\n",
    "    if negative_keys is not None:\n",
    "        if negative_mode == 'unpaired' and negative_keys.dim() != 2:\n",
    "            raise ValueError(\"<negative_keys> must have 2 dimensions if <negative_mode> == 'unpaired'.\")\n",
    "        if negative_mode == 'paired' and negative_keys.dim() != 3:\n",
    "            raise ValueError(\"<negative_keys> must have 3 dimensions if <negative_mode> == 'paired'.\")\n",
    "\n",
    "    # Check matching number of samples.\n",
    "    if len(query) != len(positive_key):\n",
    "        raise ValueError('<query> and <positive_key> must must have the same number of samples.')\n",
    "    if negative_keys is not None:\n",
    "        if negative_mode == 'paired' and len(query) != len(negative_keys):\n",
    "            raise ValueError(\"If negative_mode == 'paired', then <negative_keys> must have the same number of samples as <query>.\")\n",
    "\n",
    "    # Embedding vectors should have same number of components.\n",
    "    if query.shape[-1] != positive_key.shape[-1]:\n",
    "        raise ValueError('Vectors of <query> and <positive_key> should have the same number of components.')\n",
    "    if negative_keys is not None:\n",
    "        if query.shape[-1] != negative_keys.shape[-1]:\n",
    "            raise ValueError('Vectors of <query> and <negative_keys> should have the same number of components.')\n",
    "\n",
    "    # Normalize to unit vectors\n",
    "    query, positive_key, negative_keys = normalize(query, positive_key, negative_keys)\n",
    "    if negative_keys is not None:\n",
    "        # Explicit negative keys\n",
    "\n",
    "        # Cosine between positive pairs\n",
    "        positive_logit = torch.sum(query * positive_key, dim=1, keepdim=True)\n",
    "\n",
    "        if negative_mode == 'unpaired':\n",
    "            # Cosine between all query-negative combinations\n",
    "            negative_logits = query @ transpose(negative_keys)\n",
    "\n",
    "        elif negative_mode == 'paired':\n",
    "            query = query.unsqueeze(1)\n",
    "            negative_logits = query @ transpose(negative_keys)\n",
    "            negative_logits = negative_logits.squeeze(1)\n",
    "\n",
    "        # First index in last dimension are the positive samples\n",
    "        logits = torch.cat([positive_logit, negative_logits], dim=1)\n",
    "        labels = torch.zeros(len(logits), dtype=torch.long, device=query.device)\n",
    "    else:\n",
    "        # Negative keys are implicitly off-diagonal positive keys.\n",
    "\n",
    "        # Cosine between all combinations\n",
    "        logits = query @ transpose(positive_key)\n",
    "\n",
    "        # Positive keys are the entries on the diagonal\n",
    "        labels = torch.arange(len(query), device=query.device)\n",
    "\n",
    "    return F.cross_entropy(logits / temperature, labels, reduction=reduction)\n",
    "\n",
    "\n",
    "def transpose(x):\n",
    "    return x.transpose(-2, -1)\n",
    "\n",
    "\n",
    "def normalize(*xs):\n",
    "    return [None if x is None else F.normalize(x, dim=-1) for x in xs]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "B = 4  # Batch size\n",
    "D = 128  # Feature dimension\n",
    "N = 10  # Number of negative samples\n",
    "\n",
    "loss_1 = InfoNCE(negative_mode='paired')\n",
    "\n",
    "# Query and positive_key have shape (B, D)\n",
    "query = torch.randn(B, D)\n",
    "positive_key = torch.randn(B, D)\n",
    "\n",
    "# Negative keys have shape (B, N, D), with N negative samples per query\n",
    "negative_keys = torch.randn(B, N, D)\n",
    "\n",
    "loss = loss_1(query, positive_key, negative_keys=negative_keys)\n",
    "print(f\"InfoNCE Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trajectoryZSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
